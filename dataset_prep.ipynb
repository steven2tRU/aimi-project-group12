{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ba8d9d-5816-4e5f-a885-ad90dfcb73d5",
   "metadata": {},
   "source": [
    "This notebook creates a .h5 file containing labeled patches centered around nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c73e035-a1ad-425c-aabc-29924e85021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_P000001.xml']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from instanseg.utils.data_download import create_raw_datasets_dir, create_processed_datasets_dir, download_and_extract\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import fastremap\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from instanseg.utils.utils import show_images, _move_channel_axis\n",
    "# #aws s3 cp --no-sign-request s3://monkey-training/ ./ --recursive\n",
    "monkey_dir = Path(\"../data\") # Change this to the correct path to the root data \n",
    "\n",
    "files = sorted([\n",
    "    f for f in os.listdir(monkey_dir / \"annotations\" / \"xml\")\n",
    "    if f.startswith(\"A_\") # Only take files from the first centre: centre A\n",
    "    # if f.endswith(\".xml\") and not f.startswith(\".\") # Exclude non-xml files like the hidden .ipynb-checkpoints file\n",
    "    if f.endswith(\"01.xml\") and not f.startswith(\".\") # To test, only take the first image\n",
    "]) # File path to xml folder of annotations\n",
    "\n",
    "print(files)\n",
    "label_ids = []\n",
    "means_list = []\n",
    "annotations_dict = {}\n",
    "\n",
    "\n",
    "np.random.seed(0) # Add random seed for reproducability\n",
    "\n",
    "for file in tqdm(files): # Loop through annotations\n",
    "\n",
    "    split = np.random.choice([\"train\", \"val\"], p=[0.8, 0.2])\n",
    "\n",
    "    # Get filepath of image corresponding to the annotation\n",
    "    #print(file)\n",
    "    img_pascpg_path = Path(monkey_dir) / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\")\n",
    "    img_pasdiagnostic_path = Path(monkey_dir) / (\"images/pas-diagnostic/\" + file.split(\".\")[0] + \"_PAS_Diagnostic.tif\")\n",
    "   # img_pasoriginal_path = Path(monkey_dir) / (\"images/pas-original/\" + file.split(\".\")[0] + \"_PAS_Original.tif\")\n",
    "    ihc_path = Path(monkey_dir) / (\"images/ihc/\" + file.split(\".\")[0] + \"_IHC_CPG.tif\")\n",
    "\n",
    "    # Open the .tif files using TiffSlide\n",
    "    from tiffslide import TiffSlide\n",
    "    slidepascpg = TiffSlide(img_pascpg_path)\n",
    "    slideihc = TiffSlide(ihc_path)\n",
    "\n",
    "    # Get the actual filepath of the polygon annotation\n",
    "    tree = ET.parse(monkey_dir/(\"annotations/xml/\"+file))\n",
    "    root = tree.getroot()  # Get the root of the XML\n",
    "\n",
    "#     # if split == \"val\":\n",
    "#     #     destination_img = \"/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/validation_set/images/kidney-transplant-biopsy-wsi-pas/\"\n",
    "#     #     destination_mask = \"/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/validation_set/images/tissue-mask/\"\n",
    "        \n",
    "#     #     #move images to inference folder\n",
    "#     #     import shutil\n",
    "#     #     shutil.copy(monkey_dir / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\"), destination_img)\n",
    "#     #     shutil.copy(monkey_dir / (\"images/tissue-masks/\" + file.split(\".\")[0] + \"_mask.tif\"), destination_mask)\n",
    "        \n",
    "#     #     shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_inflammatory-cells.json\"), \n",
    "#     #     '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "#     #     shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_lymphocytes.json\"), \n",
    "#     #     '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "#     #     shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_monocytes.json\"), \n",
    "#     #     '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    annotations_dict[file] = []\n",
    "\n",
    "    # Iterate over each annotation and extract relevant information\n",
    "    for annotation in root.findall('.//Annotation'):\n",
    "        name = annotation.get('Name')\n",
    "        part_of_group = annotation.get('PartOfGroup')\n",
    "        _type = annotation.get('Type')\n",
    "      \n",
    "        if _type == \"Polygon\":\n",
    "            coords_ROI = []\n",
    "            for coordinate in annotation.findall('.//Coordinate'):\n",
    "                x = float(coordinate.get('X'))\n",
    "                y = float(coordinate.get('Y'))\n",
    "                coords_ROI.append([x, y])\n",
    "\n",
    "            coords_ROI = np.array(coords_ROI)\n",
    "\n",
    "            x_min, y_min = coords_ROI.min(axis=0)\n",
    "            x_max, y_max = coords_ROI.max(axis=0)\n",
    "            bbox_width = int(x_max - x_min)\n",
    "            bbox_height = int(y_max - y_min)\n",
    "\n",
    "            # Read the bounding box from the slide\n",
    "            rgb_data = slidepascpg.read_region(\n",
    "                (int(x_min), int(y_min)),\n",
    "                0,\n",
    "                (bbox_width, bbox_height),\n",
    "                as_array=True,\n",
    "            )\n",
    "\n",
    "            ihc_data = slideihc.read_region(\n",
    "                (int(x_min), int(y_min)),\n",
    "                0,\n",
    "                (bbox_width, bbox_height),\n",
    "                as_array=True,\n",
    "            )\n",
    "\n",
    "\n",
    "            mask = Image.new(\"L\", (bbox_width, bbox_height), 0)\n",
    "            polygon = coords_ROI - [x_min, y_min]  # Translate polygon to local bbox coordinates\n",
    "            ImageDraw.Draw(mask).polygon(polygon.flatten().tolist(), outline=1, fill=1)\n",
    "            # Convert the mask to a NumPy array\n",
    "            binary_mask = np.array(mask)\n",
    "\n",
    "            annotations_dict[file].append({ \"split\": split,\n",
    "                                            \"pas-cpg\":rgb_data,\n",
    "                                            \"ihc\":ihc_data,\n",
    "                                            \"polygon\": coords_ROI, \n",
    "                                            \"mask\": binary_mask, \n",
    "                                            \"bbox\" : [x_min, y_min, x_max, y_max], \n",
    "                                            \"dots\" : []})\n",
    "\n",
    "            #show_images(rgb_data)\n",
    "\n",
    "    for annotation in root.findall('.//Annotation'):\n",
    "        name = annotation.get('Name')\n",
    "        part_of_group = annotation.get('PartOfGroup')\n",
    "        _type = annotation.get('Type')\n",
    "        \n",
    "        if _type == \"Dot\":\n",
    "            # Find the coordinates\n",
    "            coordinates = annotation.find('.//Coordinate')\n",
    "            x = int(float(coordinates.get('X')))\n",
    "            y = int(float(coordinates.get('Y')))\n",
    "            c = 0 if part_of_group == \"lymphocytes\" else 1\n",
    "\n",
    "            for i,annotation in enumerate(annotations_dict[file]):\n",
    "                if annotation[\"bbox\"][0] < x < annotation[\"bbox\"][2] and annotation[\"bbox\"][1] < y < annotation[\"bbox\"][3]:\n",
    "                    annotations_dict[file][i][\"dots\"].append([y - annotation[\"bbox\"][1] ,x - annotation[\"bbox\"][0],c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825ccf37-6ea9-4a20-be8a-ebfffeb8aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved path: /vol/csedu-nobackup/course/IMC037_aimi/group12/notebooks/h5_datasets_test\n",
      "Exists? True\n",
      "Is directory? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/1 [00:00<?, ?it/s]/vol/csedu-nobackup/course/IMC037_aimi/group12/proto-env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/vol/csedu-nobackup/course/IMC037_aimi/group12/proto-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipykernel_2583650/3825832446.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = labels.to(device) * torch.tensor(mask).bool()\n",
      "/tmp/ipykernel_2583650/3825832446.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dots = torch.tensor(dots, dtype=torch.long)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:44<00:00, 44.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1127 out of 1239 dots. 90.96% detected\n"
     ]
    }
   ],
   "source": [
    "leukocytes_dots = 0\n",
    "detected_leukocytes = 0\n",
    "\n",
    "import os\n",
    "from pytorch_utils import get_masked_patches, _to_ndim, _to_tensor_float32\n",
    "from inference_class import _rescale_to_pixel_size\n",
    "# from instanseg.instanseg import _to_tensor_float32, _rescale_to_pixel_size\n",
    "import torchstain\n",
    "from instanseg import InstanSeg\n",
    "\n",
    "# pixel_size_precision = 0.01\n",
    "# def _rescale_to_pixel_size(image: torch.Tensor, \n",
    "#                            requested_pixel_size: float, \n",
    "#                            model_pixel_size: float,\n",
    "#                            mode: str = \"bilinear\") -> torch.Tensor:\n",
    "    \n",
    "#     original_dim = image.dim()\n",
    "\n",
    "#     image = _to_ndim(image, 4)\n",
    "\n",
    "#     scale_factor = requested_pixel_size / model_pixel_size\n",
    "\n",
    "#     if not np.allclose(scale_factor,1, pixel_size_precision): #if you change this value, you MUST modify the whole_slide_image function.\n",
    "#         image = interpolate(image, scale_factor=scale_factor, mode=mode)\n",
    "\n",
    "#     return _to_ndim(image, original_dim)\n",
    "\n",
    "# The filepath below is not used anywhere...\n",
    "os.environ[\"INSTANSEG_BIOIMAGEIO_PATH\"] = '/home/cdt/Documents/Projects/InstanSeg/instanseg_thibaut/instanseg/bioimageio_models/'\n",
    "# Path where we want the .h5 files to go\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = \"h5_datasets_test\"\n",
    "path = Path(os.environ['INSTANSEG_DATASET_PATH']).resolve()\n",
    "print(\"Resolved path:\", path)\n",
    "print(\"Exists?\", path.exists())\n",
    "print(\"Is directory?\", path.is_dir())\n",
    "\n",
    "instanseg_script = torch.jit.load(\"../instanseg.pt\")\n",
    "brightfield_nuclei = InstanSeg(instanseg_script, verbosity = 0)\n",
    "\n",
    "patch_size = 128\n",
    "destination_pixel_size = 0.5 # 2420... # WE MIGHT WANT TO EXPERIMENT WITH SETTING THIS TO A LOWER VALUE --> TO INCREASE RESOLUTION\n",
    "rescale_output = False if destination_pixel_size == 0.5 else True\n",
    "\n",
    "image_types  = [\"cpg\"]#, \"ihc\"]\n",
    "\n",
    "for image_type in image_types:\n",
    "\n",
    "  if image_type == \"cpg\":\n",
    "    image_key  = \"pas-cpg\"\n",
    "  else:\n",
    "    image_key = \"ihc\"\n",
    "\n",
    "  device = \"cpu\"\n",
    "\n",
    "  np.random.seed(0)\n",
    "  import h5py\n",
    "  with h5py.File(Path(os.environ['INSTANSEG_DATASET_PATH']) / f\"monkey_{image_type}_oneslide_metadata.h5\", \"w\") as f: # Setting the name for the .h5 file\n",
    "\n",
    "      f.attrs['class_names'] = str({\"0\": \"lymphocytes\", \"1\": \"monocytes\", \"2\" : \"other\"})  # Convert to string since HDF5 attributes must be simple types\n",
    "      f.attrs['pixel_size'] = destination_pixel_size\n",
    "\n",
    "      for split in ['train', 'val']:\n",
    "          f.create_dataset(f\"{split}/data\", shape=(0, 4, patch_size, patch_size),\n",
    "          dtype=np.uint8, maxshape=(None, 4, patch_size, patch_size),\n",
    "          chunks=(1, 4, patch_size, patch_size),)\n",
    "          f.create_dataset(f\"{split}/labels\", shape=(0, 1), dtype=np.uint8, maxshape=(None, 1))\n",
    "          f.create_dataset(f\"{split}/metadata\", shape=(0,), dtype=h5py.string_dtype(), maxshape=(None,), chunks=(1,))\n",
    "\n",
    "      for file in tqdm(annotations_dict.keys()):\n",
    "          split = annotations_dict[file][0][\"split\"]\n",
    "\n",
    "          for annotation in annotations_dict[file]:\n",
    "\n",
    "              array = _to_tensor_float32(annotation[\"pas-cpg\"])\n",
    "\n",
    "              labels , input_tensor = brightfield_nuclei.eval_medium_image(array,\n",
    "              pixel_size = 0.2420, rescale_output = rescale_output, seed_threshold = 0.05, tile_size= 1024)\n",
    "\n",
    "              dots = torch.tensor(annotation[\"dots\"]).to(device)\n",
    "              dots[:,:2] = dots[:,:2] * 0.2420 / destination_pixel_size\n",
    "\n",
    "              mask = _rescale_to_pixel_size(_to_tensor_float32(annotation[\"mask\"]), 0.2420, destination_pixel_size).to(device)\n",
    "              \n",
    "              labels = labels.to(device) * torch.tensor(mask).bool()\n",
    "              canvas = torch.zeros_like(labels)\n",
    "              dots = torch.tensor(dots, dtype=torch.long)\n",
    "              canvas[:,:,dots[:,0],dots[:,1]] = dots[:,2].float() + 1\n",
    "              monocytes = labels * torch.isin(labels,labels * (canvas == 2).float()).float()\n",
    "              lymphocytes = labels * torch.isin(labels,labels * (canvas == 1).float()).float()\n",
    "              other_cells = (labels * ~torch.isin(labels,labels * (canvas > 0).float())).float()\n",
    "\n",
    "              img_tensor = _rescale_to_pixel_size(_to_tensor_float32(annotation[image_key]), 0.2420, destination_pixel_size).byte().to(device)\n",
    "\n",
    "              assert img_tensor.shape[-2:] == labels.shape[-2:]\n",
    "              detected_leukocytes += len(torch.unique(monocytes + lymphocytes)) - 1\n",
    "              leukocytes_dots += len(dots)\n",
    "\n",
    "\n",
    "              if len(torch.unique(monocytes)) > 1:\n",
    "                crops,masks,coords = get_masked_patches(monocytes,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_monocytes =(torch.cat((crops,masks),dim= 1))\n",
    "                y_monocytes = torch.zeros(len(x_monocytes),dtype = torch.long) + 1\n",
    "                metadata_monocytes = [\n",
    "                        {\n",
    "                            \"file\": file,\n",
    "                            \"annotation_idx\": annotation.get(\"id\", None),\n",
    "                            \"class\": \"monocyte\",\n",
    "                            \"coord_row\": int(coord[0].item()),\n",
    "                            \"coord_col\": int(coord[1].item())\n",
    "                        }\n",
    "                        for coord in coords\n",
    "                    ]\n",
    "              else:\n",
    "                x_monocytes = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_monocytes = torch.zeros(0,dtype = torch.long) + 1\n",
    "                metadata_monocytes = []\n",
    "\n",
    "\n",
    "              if len(torch.unique(lymphocytes)) > 1:\n",
    "                crops,masks,coords = get_masked_patches(lymphocytes,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_lymphocytes =(torch.cat((crops,masks),dim= 1))\n",
    "                y_lymphocytes = torch.zeros(len(x_lymphocytes),dtype = torch.long) + 0\n",
    "                metadata_lymphocytes = [\n",
    "                        {\n",
    "                            \"file\": file,\n",
    "                            \"annotation_idx\": annotation.get(\"id\", None),\n",
    "                            \"class\": \"lymphocyte\",\n",
    "                            \"coord_row\": int(coord[0].item()),\n",
    "                            \"coord_col\": int(coord[1].item())\n",
    "                        }\n",
    "                        for coord in coords\n",
    "                    ]\n",
    "              else:\n",
    "                x_lymphocytes = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_lymphocytes = torch.zeros(0,dtype = torch.long) + 0\n",
    "                metadata_lymphocytes = []\n",
    "\n",
    "              if len(torch.unique(other_cells)) > 1:\n",
    "                crops,masks,coords = get_masked_patches(other_cells,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_other =(torch.cat((crops,masks),dim= 1))\n",
    "                y_other = torch.zeros(len(x_other),dtype = torch.long) + 2\n",
    "                metadata_other = [\n",
    "                        {\n",
    "                            \"file\": file,\n",
    "                            \"annotation_idx\": annotation.get(\"id\", None),\n",
    "                            \"class\": \"lymphocyte\",\n",
    "                            \"coord_row\": int(coord[0].item()),\n",
    "                            \"coord_col\": int(coord[1].item())\n",
    "                        }\n",
    "                        for coord in coords\n",
    "                    ]  \n",
    "              else:\n",
    "                x_other = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_other = torch.zeros(0,dtype = torch.long) + 2\n",
    "                metadata_other = []\n",
    "\n",
    "              x = torch.cat((x_monocytes,x_lymphocytes,x_other),dim = 0)\n",
    "              y = torch.cat((y_monocytes,y_lymphocytes,y_other),dim = 0).numpy()[:,None]\n",
    "              metadata_combined = metadata_monocytes + metadata_lymphocytes + metadata_other\n",
    "\n",
    "              if len(x) != len(y):\n",
    "                    pdb.set_trace()\n",
    "\n",
    "              data_ds = f[f\"{split}/data\"]\n",
    "              labels_ds = f[f\"{split}/labels\"]\n",
    "              metadata_ds = f[f\"{split}/metadata\"]\n",
    "\n",
    "              data_ds.resize((data_ds.shape[0] + x.shape[0],) + x.shape[1:])\n",
    "              data_ds[-x.shape[0]:, ...] = (x).cpu().numpy().astype(np.uint8)\n",
    "              labels_ds.resize((labels_ds.shape[0] + y.shape[0],) + y.shape[1:])\n",
    "              labels_ds[-y.shape[0]:, ...] = y.astype(np.uint8)\n",
    "\n",
    "              # Write metadata\n",
    "              metadata_ds.resize((metadata_ds.shape[0] + len(metadata_combined),))\n",
    "              metadata_ds[-len(metadata_combined):] = [str(m) for m in metadata_combined]\n",
    "          \n",
    "\n",
    "  undetected_percent = ( leukocytes_dots - detected_leukocytes) / leukocytes_dots\n",
    "  print(f\"Detected {detected_leukocytes} out of {leukocytes_dots} dots. { 100 - undetected_percent * 100:.2f}% detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de902d86-9bfd-4bf5-aa70-5c309adf3362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
